# Section 1: Introduction
With the currently ongoing increasing spread of information, both of verified and unverified ressources, differentiating in between fake and real news becomes a pressing issue. Especially different socio-economical groups perceive and deal with ressources differently, which can quickly lead to misinformation, if not even conspiracy theory culture.

With that being stated, the aim of this project is (in the first step) to quickly implement an out-of-the-box Machine Learning approach which correctly classifies textual data into real and fake news.

# Section 2: Literature Review
While various studies exist, mostly focusing on the capacities of CNN and LSTM architectures, more recent examples highlight the benefits of using BERT models, or - more specifically - their newer variants such as DeBERTa or RoBERTa (moreover, BERT-FND or FakeBERT).

# Section 3: Data

# Section 4: Architecture

# Section 5: Installation
Explain how to set up the project. Use lists (`-` or `*`) for steps.

## Example:
1. Clone the repository: `git clone <repo_url>`
2. Install dependencies: `pip install -r requirements.txt`


# Section 6: Usage

# Section 7: Results

# Section 9: Conclusion

# Section 10: Contributing
Provide guidelines for contributing. Use links (`[text](url)`) for references.

## Example:
- Fork the repository.
- Submit a pull request following the [contribution guidelines](CONTRIBUTING.md).
